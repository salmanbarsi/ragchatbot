{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/app/upload/pdf-reader.ts"],"sourcesContent":["\"use server\";\r\n\r\nimport PDFParser from \"pdf2json\";\r\n\r\nexport async function extractPdfText(buffer: Buffer): Promise<string> {\r\n  return new Promise((resolve, reject) => {\r\n    try {\r\n      const pdfParser = new PDFParser();\r\n\r\n      pdfParser.on(\"pdfParser_dataError\", (err:any) => {\r\n        reject(err.parserError);\r\n      });\r\n\r\n      pdfParser.on(\"pdfParser_dataReady\", (pdfData:any) => {\r\n        const pages = pdfData.formImage.Pages;\r\n        let extracted = \"\";\r\n\r\n        pages.forEach((page: any) => {\r\n          page.Texts.forEach((t: any) => {\r\n            const decoded = decodeURIComponent(\r\n              t.R.map((r: any) => r.T).join(\" \")\r\n            );\r\n            extracted += decoded + \" \";\r\n          });\r\n          extracted += \"\\n\\n\";\r\n        });\r\n\r\n        resolve(extracted);\r\n      });\r\n\r\n      pdfParser.parseBuffer(buffer);\r\n    } catch (error) {\r\n      reject(error);\r\n    }\r\n  });\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;;;;AAEO,eAAe,eAAe,MAAc;IACjD,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,IAAI;YACF,MAAM,YAAY,IAAI,wJAAS;YAE/B,UAAU,EAAE,CAAC,uBAAuB,CAAC;gBACnC,OAAO,IAAI,WAAW;YACxB;YAEA,UAAU,EAAE,CAAC,uBAAuB,CAAC;gBACnC,MAAM,QAAQ,QAAQ,SAAS,CAAC,KAAK;gBACrC,IAAI,YAAY;gBAEhB,MAAM,OAAO,CAAC,CAAC;oBACb,KAAK,KAAK,CAAC,OAAO,CAAC,CAAC;wBAClB,MAAM,UAAU,mBACd,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,IAAW,EAAE,CAAC,EAAE,IAAI,CAAC;wBAEhC,aAAa,UAAU;oBACzB;oBACA,aAAa;gBACf;gBAEA,QAAQ;YACV;YAEA,UAAU,WAAW,CAAC;QACxB,EAAE,OAAO,OAAO;YACd,OAAO;QACT;IACF;AACF;;;IA/BsB;;AAAA,+OAAA"}},
    {"offset": {"line": 107, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/lib/db-config.ts"],"sourcesContent":["import { drizzle } from \"drizzle-orm/neon-http\";\r\nimport { neon } from \"@neondatabase/serverless\";\r\nimport {config} from 'dotenv';\r\n\r\nconfig({path: '.env.local'});\r\nconst client = neon(process.env.NEON_DATABASE_URL!);\r\nexport const db = drizzle(client);\r\n\r\nexport default db;"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AAEA,IAAA,+IAAM,EAAC;IAAC,MAAM;AAAY;AAC1B,MAAM,SAAS,IAAA,8JAAI,EAAC,QAAQ,GAAG,CAAC,iBAAiB;AAC1C,MAAM,KAAK,IAAA,mKAAO,EAAC;uCAEX"}},
    {"offset": {"line": 129, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/lib/db-schema.ts"],"sourcesContent":["import { pgTable, serial, text, vector, index } from \"drizzle-orm/pg-core\";\r\n\r\nexport const documents = pgTable(\r\n  \"documents\",\r\n  {\r\n    id: serial(\"id\").primaryKey(),\r\n    content: text(\"content\").notNull(),\r\n    embedding: vector(\"embedding\", { dimensions: 1536 }),\r\n  },\r\n  (table) => [\r\n    index(\"embeddingIndex\").using(\r\n      \"hnsw\",\r\n      table.embedding.op(\"vector_cosine_ops\")\r\n    ),\r\n  ]\r\n);\r\n\r\nexport type InsertDocument = typeof documents.$inferInsert;\r\nexport type SelectDocument = typeof documents.$inferSelect;"],"names":[],"mappings":";;;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEO,MAAM,YAAY,IAAA,gKAAO,EAC9B,aACA;IACE,IAAI,IAAA,2KAAM,EAAC,MAAM,UAAU;IAC3B,SAAS,IAAA,uKAAI,EAAC,WAAW,OAAO;IAChC,WAAW,IAAA,+LAAM,EAAC,aAAa;QAAE,YAAY;IAAK;AACpD,GACA,CAAC,QAAU;QACT,IAAA,gKAAK,EAAC,kBAAkB,KAAK,CAC3B,QACA,MAAM,SAAS,CAAC,EAAE,CAAC;KAEtB"}},
    {"offset": {"line": 152, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/lib/embeddings.ts"],"sourcesContent":["import { embed, embedMany } from \"ai\";\r\nimport { createOpenRouter } from \"@openrouter/ai-sdk-provider\";\r\n\r\nconst openrouter = createOpenRouter({\r\n  apiKey: process.env.OPENROUTER_API_KEY!,  \r\n});\r\n\r\nexport async function genrateEmbeddings(text: string) {\r\n    const input = text.replace(\"\\n\", \" \");\r\n\r\n    const { embedding } = await embed({\r\n        model: openrouter.textEmbeddingModel(\"nvidia/nemotron-embed-6b:free\"),\r\n        value: input,\r\n    });\r\n    return embedding;\r\n}\r\n\r\nexport async function genrateEmbeddingsMany(texts: string[]) {\r\n    const inputs = texts.map((text) => text.replace(\"\\n\", \" \"));\r\n    const { embeddings } = await embedMany({\r\n        model: openrouter.textEmbeddingModel(\"nvidia/nemotron-embed-6b:free\"),\r\n        values: inputs,\r\n    });\r\n    return embeddings;\r\n}"],"names":[],"mappings":";;;;;;AAAA;AACA;;;AAEA,MAAM,aAAa,IAAA,2LAAgB,EAAC;IAClC,QAAQ,QAAQ,GAAG,CAAC,kBAAkB;AACxC;AAEO,eAAe,kBAAkB,IAAY;IAChD,MAAM,QAAQ,KAAK,OAAO,CAAC,MAAM;IAEjC,MAAM,EAAE,SAAS,EAAE,GAAG,MAAM,IAAA,6JAAK,EAAC;QAC9B,OAAO,WAAW,kBAAkB,CAAC;QACrC,OAAO;IACX;IACA,OAAO;AACX;AAEO,eAAe,sBAAsB,KAAe;IACvD,MAAM,SAAS,MAAM,GAAG,CAAC,CAAC,OAAS,KAAK,OAAO,CAAC,MAAM;IACtD,MAAM,EAAE,UAAU,EAAE,GAAG,MAAM,IAAA,iKAAS,EAAC;QACnC,OAAO,WAAW,kBAAkB,CAAC;QACrC,QAAQ;IACZ;IACA,OAAO;AACX"}},
    {"offset": {"line": 185, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/lib/chunking.ts"],"sourcesContent":["import { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\r\n\r\nexport const textSplitter = new RecursiveCharacterTextSplitter({\r\n    chunkSize: 150,\r\n    chunkOverlap: 20,\r\n    separators: [\"\"],\r\n});\r\n\r\nexport async function chunkcontent(content: string) {\r\n    return await textSplitter.splitText(content.trim());\r\n}"],"names":[],"mappings":";;;;;;AAAA;AAAA;;AAEO,MAAM,eAAe,IAAI,uMAA8B,CAAC;IAC3D,WAAW;IACX,cAAc;IACd,YAAY;QAAC;KAAG;AACpB;AAEO,eAAe,aAAa,OAAe;IAC9C,OAAO,MAAM,aAAa,SAAS,CAAC,QAAQ,IAAI;AACpD"}},
    {"offset": {"line": 208, "column": 0}, "map": {"version":3,"sources":["file:///D:/Nxtjs/rag-chatbot/src/app/upload/actions.ts"],"sourcesContent":["\"use server\";\r\n\r\nimport { extractPdfText } from \"./pdf-reader\";\r\nimport { db } from \"@/lib/db-config\";\r\nimport { documents } from \"@/lib/db-schema\";\r\nimport { genrateEmbeddingsMany } from \"@/lib/embeddings\";\r\nimport { chunkcontent } from \"@/lib/chunking\";\r\n\r\nexport async function processpdfFile(formData: FormData) {\r\n  try {\r\n    const file = formData.get(\"pdf\") as File;\r\n    const buffer = Buffer.from(await file.arrayBuffer());\r\n\r\n    // EXTRACT TEXT (works 100%)\r\n    const text = await extractPdfText(buffer);\r\n    console.log(text)\r\n\r\n    if (!text.trim()) {\r\n      return {\r\n        success: false,\r\n        error: \"No extractable text found in PDF.\",\r\n      };\r\n    }\r\n\r\n    const chunks:any = chunkcontent(text);\r\n    const embeddings = await genrateEmbeddingsMany(chunks);\r\n\r\n    await db.insert(documents).values(\r\n      chunks.map(({chunk, index}:any) => ({\r\n        content: chunk,\r\n        embedding: embeddings[index],\r\n      }))\r\n    );\r\n\r\n    return {\r\n      success: true,\r\n      message: \"PDF processed and stored successfully!\",\r\n    };\r\n  } catch (error) {\r\n    console.error(\"Error processing PDF file:\", error);\r\n    return {\r\n      success: false,\r\n      error: \"Failed to process PDF file.\",\r\n    };\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;AAEO,eAAe,eAAe,QAAkB;IACrD,IAAI;QACF,MAAM,OAAO,SAAS,GAAG,CAAC;QAC1B,MAAM,SAAS,OAAO,IAAI,CAAC,MAAM,KAAK,WAAW;QAEjD,4BAA4B;QAC5B,MAAM,OAAO,MAAM,IAAA,uJAAc,EAAC;QAClC,QAAQ,GAAG,CAAC;QAEZ,IAAI,CAAC,KAAK,IAAI,IAAI;YAChB,OAAO;gBACL,SAAS;gBACT,OAAO;YACT;QACF;QAEA,MAAM,SAAa,IAAA,sIAAY,EAAC;QAChC,MAAM,aAAa,MAAM,IAAA,iJAAqB,EAAC;QAE/C,MAAM,gIAAE,CAAC,MAAM,CAAC,uIAAS,EAAE,MAAM,CAC/B,OAAO,GAAG,CAAC,CAAC,EAAC,KAAK,EAAE,KAAK,EAAK,GAAK,CAAC;gBAClC,SAAS;gBACT,WAAW,UAAU,CAAC,MAAM;YAC9B,CAAC;QAGH,OAAO;YACL,SAAS;YACT,SAAS;QACX;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,8BAA8B;QAC5C,OAAO;YACL,SAAS;YACT,OAAO;QACT;IACF;AACF;;;IArCsB;;AAAA,+OAAA"}}]
}